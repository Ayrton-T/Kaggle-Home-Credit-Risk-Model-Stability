{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, cross_validate\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score, auc\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier, LGBMRegressor\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcat\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import roc_auc_score, auc\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "import catboost as cat\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_pandas(df):\n",
    "    df = df.to_pandas().set_index('case_id')\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    return df\n",
    "\n",
    "def reduce_memory_usage_pl(df):\n",
    "        \"\"\" Reduce memory usage by polars dataframe {df} with name {name} by changing its data types.\n",
    "            Original pandas version of this function: https://www.kaggle.com/code/arjanso/reducing-dataframe-memory-size-by-65 \"\"\"\n",
    "        print(f\"Memory usage of dataframe is {round(df.estimated_size('mb'), 2)} MB\")\n",
    "        Numeric_Int_types = [pl.Int8,pl.Int16,pl.Int32,pl.Int64]\n",
    "        Numeric_Float_types = [pl.Float32,pl.Float64]    \n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                col_type = df[col].dtype\n",
    "                if col_type == pl.Categorical:\n",
    "                    continue\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "                if col_type in Numeric_Int_types:\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df = df.with_columns(df[col].cast(pl.Int8))\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df = df.with_columns(df[col].cast(pl.Int16))\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df = df.with_columns(df[col].cast(pl.Int32))\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df = df.with_columns(df[col].cast(pl.Int64))\n",
    "                elif col_type in Numeric_Float_types:\n",
    "                    if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df = df.with_columns(df[col].cast(pl.Float32))\n",
    "                    else:\n",
    "                        pass\n",
    "                # elif col_type == pl.Utf8:\n",
    "                #     df = df.with_columns(df[col].cast(pl.Categorical))\n",
    "                else:\n",
    "                    pass\n",
    "            except:\n",
    "                pass\n",
    "        print(f\"Memory usage of dataframe became {round(df.estimated_size('mb'), 2)} MB\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK_NUM</th>\n",
       "      <th>actualdpdtolerance_344P</th>\n",
       "      <th>amtinstpaidbefduel24m_4187115A</th>\n",
       "      <th>annuity_780A</th>\n",
       "      <th>annuitynextmonth_57A</th>\n",
       "      <th>applicationcnt_361L</th>\n",
       "      <th>applications30d_658L</th>\n",
       "      <th>applicationscnt_1086L</th>\n",
       "      <th>applicationscnt_464L</th>\n",
       "      <th>...</th>\n",
       "      <th>pmtcount_4527229L</th>\n",
       "      <th>pmtcount_4955617L</th>\n",
       "      <th>pmtcount_693L</th>\n",
       "      <th>pmtscount_423L</th>\n",
       "      <th>pmtssum_45A</th>\n",
       "      <th>requesttype_4525192L</th>\n",
       "      <th>riskassesment_302T</th>\n",
       "      <th>riskassesment_940T</th>\n",
       "      <th>secondquarter_766L</th>\n",
       "      <th>thirdquarter_1082L</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1917.599976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3134.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4937.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4643.600098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3390.199951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198095</th>\n",
       "      <td>202001</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74224.000000</td>\n",
       "      <td>10817.400391</td>\n",
       "      <td>12267.600586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PENSION_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198096</th>\n",
       "      <td>202001</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185840.578125</td>\n",
       "      <td>6963.399902</td>\n",
       "      <td>1377.599976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PENSION_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198097</th>\n",
       "      <td>202001</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182969.796875</td>\n",
       "      <td>2315.600098</td>\n",
       "      <td>7800.800293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEDUCTION_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198098</th>\n",
       "      <td>202001</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60266.601562</td>\n",
       "      <td>6512.600098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEDUCTION_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198099</th>\n",
       "      <td>202001</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128475.765625</td>\n",
       "      <td>3828.400146</td>\n",
       "      <td>3134.600098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PENSION_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152666 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MONTH  WEEK_NUM  actualdpdtolerance_344P  \\\n",
       "case_id                                              \n",
       "0        201901         0                      NaN   \n",
       "1        201901         0                      NaN   \n",
       "2        201901         0                      NaN   \n",
       "3        201901         0                      NaN   \n",
       "4        201901         0                      NaN   \n",
       "...         ...       ...                      ...   \n",
       "198095   202001        55                      0.0   \n",
       "198096   202001        55                      0.0   \n",
       "198097   202001        55                      0.0   \n",
       "198098   202001        55                      0.0   \n",
       "198099   202001        55                      0.0   \n",
       "\n",
       "         amtinstpaidbefduel24m_4187115A  annuity_780A  annuitynextmonth_57A  \\\n",
       "case_id                                                                       \n",
       "0                                   NaN   1917.599976              0.000000   \n",
       "1                                   NaN   3134.000000              0.000000   \n",
       "2                                   NaN   4937.000000              0.000000   \n",
       "3                                   NaN   4643.600098              0.000000   \n",
       "4                                   NaN   3390.199951              0.000000   \n",
       "...                                 ...           ...                   ...   \n",
       "198095                     74224.000000  10817.400391          12267.600586   \n",
       "198096                    185840.578125   6963.399902           1377.599976   \n",
       "198097                    182969.796875   2315.600098           7800.800293   \n",
       "198098                     60266.601562   6512.600098              0.000000   \n",
       "198099                    128475.765625   3828.400146           3134.600098   \n",
       "\n",
       "         applicationcnt_361L  applications30d_658L  applicationscnt_1086L  \\\n",
       "case_id                                                                     \n",
       "0                        0.0                   0.0                    0.0   \n",
       "1                        0.0                   0.0                    0.0   \n",
       "2                        0.0                   0.0                    0.0   \n",
       "3                        0.0                   1.0                    0.0   \n",
       "4                        0.0                   1.0                    0.0   \n",
       "...                      ...                   ...                    ...   \n",
       "198095                   0.0                   0.0                    0.0   \n",
       "198096                   0.0                   0.0                    1.0   \n",
       "198097                   0.0                   3.0                    9.0   \n",
       "198098                   0.0                   0.0                    0.0   \n",
       "198099                   0.0                   0.0                    0.0   \n",
       "\n",
       "         applicationscnt_464L  ...  pmtcount_4527229L  pmtcount_4955617L  \\\n",
       "case_id                        ...                                         \n",
       "0                         0.0  ...                NaN                NaN   \n",
       "1                         0.0  ...                NaN                NaN   \n",
       "2                         0.0  ...                NaN                NaN   \n",
       "3                         2.0  ...                NaN                NaN   \n",
       "4                         0.0  ...                NaN                NaN   \n",
       "...                       ...  ...                ...                ...   \n",
       "198095                    0.0  ...                6.0                NaN   \n",
       "198096                    0.0  ...                6.0                NaN   \n",
       "198097                    0.0  ...                NaN                NaN   \n",
       "198098                    6.0  ...                NaN                NaN   \n",
       "198099                    0.0  ...                6.0                NaN   \n",
       "\n",
       "         pmtcount_693L  pmtscount_423L  pmtssum_45A  requesttype_4525192L  \\\n",
       "case_id                                                                     \n",
       "0                  NaN             NaN          NaN                   NaN   \n",
       "1                  NaN             NaN          NaN                   NaN   \n",
       "2                  NaN             NaN          NaN                   NaN   \n",
       "3                  NaN             NaN          NaN                   NaN   \n",
       "4                  NaN             NaN          NaN                   NaN   \n",
       "...                ...             ...          ...                   ...   \n",
       "198095             NaN             NaN          NaN             PENSION_6   \n",
       "198096             NaN             NaN          NaN             PENSION_6   \n",
       "198097             NaN             NaN          NaN           DEDUCTION_6   \n",
       "198098             NaN             NaN          NaN           DEDUCTION_6   \n",
       "198099             NaN             NaN          NaN             PENSION_6   \n",
       "\n",
       "         riskassesment_302T  riskassesment_940T  secondquarter_766L  \\\n",
       "case_id                                                               \n",
       "0                       NaN                 NaN                 NaN   \n",
       "1                       NaN                 NaN                 NaN   \n",
       "2                       NaN                 NaN                 NaN   \n",
       "3                       NaN                 NaN                 NaN   \n",
       "4                       NaN                 NaN                 NaN   \n",
       "...                     ...                 ...                 ...   \n",
       "198095                  NaN                 NaN                 0.0   \n",
       "198096                  NaN                 NaN                 9.0   \n",
       "198097                  NaN                 NaN                 NaN   \n",
       "198098                  NaN                 NaN                 0.0   \n",
       "198099                  NaN                 NaN                 1.0   \n",
       "\n",
       "         thirdquarter_1082L  \n",
       "case_id                      \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  \n",
       "...                     ...  \n",
       "198095                  5.0  \n",
       "198096                  9.0  \n",
       "198097                  NaN  \n",
       "198098                  2.0  \n",
       "198099                  2.0  \n",
       "\n",
       "[152666 rows x 195 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pl.read_parquet('dataset/train_sample_first_ten.parquet')\n",
    "\n",
    "# data = pl.read_parquet('dataset/train_filter_features_sample_first_ten.parquet')\n",
    "# get_label = pl.read_parquet('dataset/train_sample_first_ten.parquet')\n",
    "\n",
    "# data = reduce_memory_usage_pl(data)\n",
    "data = _to_pandas(data)\n",
    "# label = _to_pandas(get_label)['target']\n",
    "\n",
    "label = data['target']\n",
    "data = data.drop(columns=['target'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(data, label, test_size=0.3, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_features = [col for col in data.columns if data[col].dtype.name == 'category' or data[col].dtype.name == 'object']\n",
    "# cat_features\n",
    "\n",
    "# onehot = pd.get_dummies(data, columns=cat_features)\n",
    "# onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\Lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.711079\n",
      "[200]\tvalid_0's auc: 0.713816\n",
      "[300]\tvalid_0's auc: 0.715256\n",
      "[400]\tvalid_0's auc: 0.716247\n",
      "[500]\tvalid_0's auc: 0.71731\n",
      "[600]\tvalid_0's auc: 0.718331\n",
      "[700]\tvalid_0's auc: 0.719078\n",
      "[800]\tvalid_0's auc: 0.720102\n",
      "[900]\tvalid_0's auc: 0.720713\n",
      "[1000]\tvalid_0's auc: 0.721517\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's auc: 0.721517\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(x_train, label=y_train)\n",
    "lgb_valid = lgb.Dataset(x_valid, label=y_valid, reference=lgb_train)\n",
    "\n",
    "lgb_params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"max_depth\": 10,\n",
    "    \"num_leaves\": 64,\n",
    "    \"min_data_in_leaf\": 10,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"feature_fraction\": 0.5,\n",
    "    \"bagging_fraction\": 0.5,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"n_estimators\": 1000,\n",
    "    'min_data_in_bin':1,\n",
    "    'max_bin': 64,\n",
    "    \"verbose\": -1,\n",
    "    \"random_state\": 42, \n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "cls = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_train,\n",
    "    valid_sets=lgb_valid,\n",
    "    callbacks=[lgb.log_evaluation(100), lgb.early_stopping(100)]\n",
    ")\n",
    "pred = cls.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7215174606732623"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true=y_valid, y_score=pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.59432\n",
      "[1]\tvalidation_0-auc:0.62403\n",
      "[2]\tvalidation_0-auc:0.64444\n",
      "[3]\tvalidation_0-auc:0.64813\n",
      "[4]\tvalidation_0-auc:0.65703\n",
      "[5]\tvalidation_0-auc:0.66202\n",
      "[6]\tvalidation_0-auc:0.66485\n",
      "[7]\tvalidation_0-auc:0.67009\n",
      "[8]\tvalidation_0-auc:0.67642\n",
      "[9]\tvalidation_0-auc:0.67721\n",
      "[10]\tvalidation_0-auc:0.67944\n",
      "[11]\tvalidation_0-auc:0.68028\n",
      "[12]\tvalidation_0-auc:0.68067\n",
      "[13]\tvalidation_0-auc:0.68104\n",
      "[14]\tvalidation_0-auc:0.68077\n",
      "[15]\tvalidation_0-auc:0.68003\n",
      "[16]\tvalidation_0-auc:0.68037\n",
      "[17]\tvalidation_0-auc:0.68074\n",
      "[18]\tvalidation_0-auc:0.68051\n",
      "[19]\tvalidation_0-auc:0.68144\n",
      "[20]\tvalidation_0-auc:0.68122\n",
      "[21]\tvalidation_0-auc:0.68215\n",
      "[22]\tvalidation_0-auc:0.68035\n",
      "[23]\tvalidation_0-auc:0.67936\n",
      "[24]\tvalidation_0-auc:0.67740\n",
      "[25]\tvalidation_0-auc:0.67506\n",
      "[26]\tvalidation_0-auc:0.67466\n",
      "[27]\tvalidation_0-auc:0.67411\n",
      "[28]\tvalidation_0-auc:0.67356\n",
      "[29]\tvalidation_0-auc:0.67293\n",
      "[30]\tvalidation_0-auc:0.67255\n",
      "[31]\tvalidation_0-auc:0.67253\n",
      "[32]\tvalidation_0-auc:0.67164\n",
      "[33]\tvalidation_0-auc:0.67166\n",
      "[34]\tvalidation_0-auc:0.67134\n",
      "[35]\tvalidation_0-auc:0.67029\n",
      "[36]\tvalidation_0-auc:0.67117\n",
      "[37]\tvalidation_0-auc:0.67070\n",
      "[38]\tvalidation_0-auc:0.67093\n",
      "[39]\tvalidation_0-auc:0.67030\n",
      "[40]\tvalidation_0-auc:0.66995\n",
      "[41]\tvalidation_0-auc:0.66985\n",
      "[42]\tvalidation_0-auc:0.66915\n",
      "[43]\tvalidation_0-auc:0.67000\n",
      "[44]\tvalidation_0-auc:0.66877\n",
      "[45]\tvalidation_0-auc:0.66818\n",
      "[46]\tvalidation_0-auc:0.66738\n",
      "[47]\tvalidation_0-auc:0.66691\n",
      "[48]\tvalidation_0-auc:0.66776\n",
      "[49]\tvalidation_0-auc:0.66785\n",
      "[50]\tvalidation_0-auc:0.66839\n",
      "[51]\tvalidation_0-auc:0.66900\n",
      "[52]\tvalidation_0-auc:0.66872\n",
      "[53]\tvalidation_0-auc:0.67028\n",
      "[54]\tvalidation_0-auc:0.67095\n",
      "[55]\tvalidation_0-auc:0.67058\n",
      "[56]\tvalidation_0-auc:0.66954\n",
      "[57]\tvalidation_0-auc:0.67027\n",
      "[58]\tvalidation_0-auc:0.67072\n",
      "[59]\tvalidation_0-auc:0.67099\n",
      "[60]\tvalidation_0-auc:0.67075\n",
      "[61]\tvalidation_0-auc:0.67015\n",
      "[62]\tvalidation_0-auc:0.67057\n",
      "[63]\tvalidation_0-auc:0.67021\n",
      "[64]\tvalidation_0-auc:0.67044\n",
      "[65]\tvalidation_0-auc:0.67051\n",
      "[66]\tvalidation_0-auc:0.67061\n",
      "[67]\tvalidation_0-auc:0.66993\n",
      "[68]\tvalidation_0-auc:0.66953\n",
      "[69]\tvalidation_0-auc:0.66985\n",
      "[70]\tvalidation_0-auc:0.66966\n",
      "[71]\tvalidation_0-auc:0.66932\n",
      "[72]\tvalidation_0-auc:0.66954\n",
      "[73]\tvalidation_0-auc:0.66928\n",
      "[74]\tvalidation_0-auc:0.66999\n",
      "[75]\tvalidation_0-auc:0.67027\n",
      "[76]\tvalidation_0-auc:0.66969\n",
      "[77]\tvalidation_0-auc:0.66899\n",
      "[78]\tvalidation_0-auc:0.66879\n",
      "[79]\tvalidation_0-auc:0.66921\n",
      "[80]\tvalidation_0-auc:0.66971\n",
      "[81]\tvalidation_0-auc:0.67032\n",
      "[82]\tvalidation_0-auc:0.67104\n",
      "[83]\tvalidation_0-auc:0.67090\n",
      "[84]\tvalidation_0-auc:0.67093\n",
      "[85]\tvalidation_0-auc:0.67137\n",
      "[86]\tvalidation_0-auc:0.67160\n",
      "[87]\tvalidation_0-auc:0.67174\n",
      "[88]\tvalidation_0-auc:0.67155\n",
      "[89]\tvalidation_0-auc:0.67143\n",
      "[90]\tvalidation_0-auc:0.67142\n",
      "[91]\tvalidation_0-auc:0.67124\n",
      "[92]\tvalidation_0-auc:0.67145\n",
      "[93]\tvalidation_0-auc:0.67135\n",
      "[94]\tvalidation_0-auc:0.67156\n",
      "[95]\tvalidation_0-auc:0.67187\n",
      "[96]\tvalidation_0-auc:0.67197\n",
      "[97]\tvalidation_0-auc:0.67124\n",
      "[98]\tvalidation_0-auc:0.67128\n",
      "[99]\tvalidation_0-auc:0.67101\n",
      "[100]\tvalidation_0-auc:0.67103\n",
      "[101]\tvalidation_0-auc:0.67142\n",
      "[102]\tvalidation_0-auc:0.67133\n",
      "[103]\tvalidation_0-auc:0.67114\n",
      "[104]\tvalidation_0-auc:0.67112\n",
      "[105]\tvalidation_0-auc:0.67088\n",
      "[106]\tvalidation_0-auc:0.67109\n",
      "[107]\tvalidation_0-auc:0.67147\n",
      "[108]\tvalidation_0-auc:0.67126\n",
      "[109]\tvalidation_0-auc:0.67116\n",
      "[110]\tvalidation_0-auc:0.67082\n",
      "[111]\tvalidation_0-auc:0.67070\n",
      "[112]\tvalidation_0-auc:0.67074\n",
      "[113]\tvalidation_0-auc:0.67069\n",
      "[114]\tvalidation_0-auc:0.67080\n",
      "[115]\tvalidation_0-auc:0.67068\n",
      "[116]\tvalidation_0-auc:0.67066\n",
      "[117]\tvalidation_0-auc:0.67073\n",
      "[118]\tvalidation_0-auc:0.67049\n",
      "[119]\tvalidation_0-auc:0.66998\n",
      "[120]\tvalidation_0-auc:0.66976\n",
      "[121]\tvalidation_0-auc:0.66952\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=20, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=20, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device='cuda', early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric='auc', feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=20, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    device=\"cuda\",\n",
    "    objective='binary:logistic',\n",
    "    tree_method=\"hist\",\n",
    "    enable_categorical=True,\n",
    "    eval_metric='auc',\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=1,\n",
    "    max_depth=20,\n",
    "    # gamma=0.7,\n",
    "    # reg_alpha=0.7,\n",
    "    n_estimators=1200,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Training the model on the training data\n",
    "xgb_model.fit(\n",
    "    x_train, y_train,\n",
    "    eval_set=[(x_valid, y_valid)],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6821496278705355"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pred = xgb_model.predict_proba(x_valid)[:,1]\n",
    "roc_auc_score(y_true=y_valid, y_score=xgb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6215030\tbest: 0.6215030 (0)\ttotal: 319ms\tremaining: 6m 22s\n",
      "1:\ttotal: 633ms\tremaining: 6m 18s\n",
      "2:\ttotal: 949ms\tremaining: 6m 18s\n",
      "3:\ttotal: 1.27s\tremaining: 6m 20s\n",
      "4:\ttotal: 1.58s\tremaining: 6m 18s\n",
      "5:\ttest: 0.6757965\tbest: 0.6757965 (5)\ttotal: 1.89s\tremaining: 6m 16s\n",
      "6:\ttotal: 2.2s\tremaining: 6m 15s\n",
      "7:\ttotal: 2.53s\tremaining: 6m 17s\n",
      "8:\ttotal: 2.85s\tremaining: 6m 16s\n",
      "9:\ttotal: 3.17s\tremaining: 6m 17s\n",
      "10:\ttest: 0.6910733\tbest: 0.6910733 (10)\ttotal: 3.48s\tremaining: 6m 16s\n",
      "11:\ttotal: 3.8s\tremaining: 6m 16s\n",
      "12:\ttotal: 4.12s\tremaining: 6m 16s\n",
      "13:\ttotal: 4.44s\tremaining: 6m 16s\n",
      "14:\ttotal: 4.78s\tremaining: 6m 17s\n",
      "15:\ttest: 0.6969195\tbest: 0.6969195 (15)\ttotal: 5.11s\tremaining: 6m 18s\n",
      "16:\ttotal: 5.43s\tremaining: 6m 17s\n",
      "17:\ttotal: 5.74s\tremaining: 6m 17s\n",
      "18:\ttotal: 6.07s\tremaining: 6m 17s\n",
      "19:\ttotal: 6.39s\tremaining: 6m 16s\n",
      "20:\ttest: 0.7044605\tbest: 0.7047380 (19)\ttotal: 6.72s\tremaining: 6m 17s\n",
      "21:\ttotal: 7.04s\tremaining: 6m 16s\n",
      "22:\ttotal: 7.37s\tremaining: 6m 17s\n",
      "23:\ttotal: 7.69s\tremaining: 6m 16s\n",
      "24:\ttotal: 8.02s\tremaining: 6m 16s\n",
      "25:\ttest: 0.7104898\tbest: 0.7104898 (25)\ttotal: 8.36s\tremaining: 6m 17s\n",
      "26:\ttotal: 8.7s\tremaining: 6m 17s\n",
      "27:\ttotal: 9.01s\tremaining: 6m 17s\n",
      "28:\ttotal: 9.33s\tremaining: 6m 16s\n",
      "29:\ttotal: 9.65s\tremaining: 6m 16s\n",
      "30:\ttest: 0.7105073\tbest: 0.7110299 (28)\ttotal: 9.97s\tremaining: 6m 16s\n",
      "31:\ttotal: 10.3s\tremaining: 6m 15s\n",
      "32:\ttotal: 10.6s\tremaining: 6m 15s\n",
      "33:\ttotal: 10.9s\tremaining: 6m 15s\n",
      "34:\ttotal: 11.2s\tremaining: 6m 14s\n",
      "35:\ttest: 0.7093477\tbest: 0.7110299 (28)\ttotal: 11.6s\tremaining: 6m 13s\n",
      "36:\ttotal: 11.9s\tremaining: 6m 13s\n",
      "37:\ttotal: 12.2s\tremaining: 6m 12s\n",
      "38:\ttotal: 12.5s\tremaining: 6m 12s\n",
      "39:\ttotal: 12.8s\tremaining: 6m 12s\n",
      "40:\ttest: 0.7114077\tbest: 0.7116893 (39)\ttotal: 13.2s\tremaining: 6m 11s\n",
      "41:\ttotal: 13.5s\tremaining: 6m 11s\n",
      "42:\ttotal: 13.8s\tremaining: 6m 10s\n",
      "43:\ttotal: 14.1s\tremaining: 6m 10s\n",
      "44:\ttotal: 14.4s\tremaining: 6m 10s\n",
      "45:\ttest: 0.7113589\tbest: 0.7116893 (39)\ttotal: 14.8s\tremaining: 6m 10s\n",
      "46:\ttotal: 15.1s\tremaining: 6m 9s\n",
      "47:\ttotal: 15.4s\tremaining: 6m 9s\n",
      "48:\ttotal: 15.7s\tremaining: 6m 8s\n",
      "49:\ttotal: 16s\tremaining: 6m 8s\n",
      "50:\ttest: 0.7143216\tbest: 0.7143216 (50)\ttotal: 16.3s\tremaining: 6m 8s\n",
      "51:\ttotal: 16.7s\tremaining: 6m 7s\n",
      "52:\ttotal: 17s\tremaining: 6m 7s\n",
      "53:\ttotal: 17.3s\tremaining: 6m 6s\n",
      "54:\ttotal: 17.6s\tremaining: 6m 6s\n",
      "55:\ttest: 0.7150225\tbest: 0.7150225 (55)\ttotal: 17.9s\tremaining: 6m 6s\n",
      "56:\ttotal: 18.2s\tremaining: 6m 5s\n",
      "57:\ttotal: 18.6s\tremaining: 6m 5s\n",
      "58:\ttotal: 18.9s\tremaining: 6m 5s\n",
      "59:\ttotal: 19.2s\tremaining: 6m 4s\n",
      "60:\ttest: 0.7162651\tbest: 0.7162651 (60)\ttotal: 19.5s\tremaining: 6m 4s\n",
      "61:\ttotal: 19.8s\tremaining: 6m 4s\n",
      "62:\ttotal: 20.1s\tremaining: 6m 3s\n",
      "63:\ttotal: 20.5s\tremaining: 6m 3s\n",
      "64:\ttotal: 20.8s\tremaining: 6m 2s\n",
      "65:\ttest: 0.7165436\tbest: 0.7166247 (64)\ttotal: 21.1s\tremaining: 6m 2s\n",
      "66:\ttotal: 21.4s\tremaining: 6m 2s\n",
      "67:\ttotal: 21.7s\tremaining: 6m 1s\n",
      "68:\ttotal: 22s\tremaining: 6m 1s\n",
      "69:\ttotal: 22.4s\tremaining: 6m\n",
      "70:\ttest: 0.7168656\tbest: 0.7168656 (70)\ttotal: 22.7s\tremaining: 6m\n",
      "71:\ttotal: 23s\tremaining: 5m 59s\n",
      "72:\ttotal: 23.3s\tremaining: 5m 59s\n",
      "73:\ttotal: 23.6s\tremaining: 5m 59s\n",
      "74:\ttotal: 23.9s\tremaining: 5m 59s\n",
      "75:\ttest: 0.7171867\tbest: 0.7171867 (75)\ttotal: 24.3s\tremaining: 5m 58s\n",
      "76:\ttotal: 24.6s\tremaining: 5m 58s\n",
      "77:\ttotal: 24.9s\tremaining: 5m 57s\n",
      "78:\ttotal: 25.2s\tremaining: 5m 57s\n",
      "79:\ttotal: 25.5s\tremaining: 5m 57s\n",
      "80:\ttest: 0.7177956\tbest: 0.7177956 (80)\ttotal: 25.8s\tremaining: 5m 57s\n",
      "81:\ttotal: 26.1s\tremaining: 5m 56s\n",
      "82:\ttotal: 26.5s\tremaining: 5m 56s\n",
      "83:\ttotal: 26.8s\tremaining: 5m 55s\n",
      "84:\ttotal: 27.1s\tremaining: 5m 55s\n",
      "85:\ttest: 0.7183742\tbest: 0.7183742 (85)\ttotal: 27.4s\tremaining: 5m 55s\n",
      "86:\ttotal: 27.7s\tremaining: 5m 54s\n",
      "87:\ttotal: 28s\tremaining: 5m 54s\n",
      "88:\ttotal: 28.3s\tremaining: 5m 53s\n",
      "89:\ttotal: 28.7s\tremaining: 5m 53s\n",
      "90:\ttest: 0.7185297\tbest: 0.7185297 (90)\ttotal: 29s\tremaining: 5m 53s\n",
      "91:\ttotal: 29.3s\tremaining: 5m 52s\n",
      "92:\ttotal: 29.6s\tremaining: 5m 52s\n",
      "93:\ttotal: 29.9s\tremaining: 5m 52s\n",
      "94:\ttotal: 30.2s\tremaining: 5m 51s\n",
      "95:\ttest: 0.7182015\tbest: 0.7185297 (90)\ttotal: 30.6s\tremaining: 5m 51s\n",
      "96:\ttotal: 30.9s\tremaining: 5m 50s\n",
      "97:\ttotal: 31.2s\tremaining: 5m 50s\n",
      "98:\ttotal: 31.5s\tremaining: 5m 50s\n",
      "99:\ttotal: 31.8s\tremaining: 5m 50s\n",
      "100:\ttest: 0.7175417\tbest: 0.7185297 (90)\ttotal: 32.1s\tremaining: 5m 49s\n",
      "101:\ttotal: 32.4s\tremaining: 5m 48s\n",
      "102:\ttotal: 32.7s\tremaining: 5m 48s\n",
      "103:\ttotal: 33s\tremaining: 5m 47s\n",
      "104:\ttotal: 33.3s\tremaining: 5m 47s\n",
      "105:\ttest: 0.7176763\tbest: 0.7185297 (90)\ttotal: 33.6s\tremaining: 5m 46s\n",
      "106:\ttotal: 33.9s\tremaining: 5m 45s\n",
      "107:\ttotal: 34.2s\tremaining: 5m 45s\n",
      "108:\ttotal: 34.5s\tremaining: 5m 44s\n",
      "109:\ttotal: 34.7s\tremaining: 5m 44s\n",
      "110:\ttest: 0.7174378\tbest: 0.7185297 (90)\ttotal: 35s\tremaining: 5m 43s\n",
      "111:\ttotal: 35.3s\tremaining: 5m 43s\n",
      "112:\ttotal: 35.6s\tremaining: 5m 42s\n",
      "113:\ttotal: 35.9s\tremaining: 5m 42s\n",
      "114:\ttotal: 36.2s\tremaining: 5m 41s\n",
      "115:\ttest: 0.7174106\tbest: 0.7185297 (90)\ttotal: 36.5s\tremaining: 5m 41s\n",
      "116:\ttotal: 36.8s\tremaining: 5m 40s\n",
      "117:\ttotal: 37.1s\tremaining: 5m 40s\n",
      "118:\ttotal: 37.4s\tremaining: 5m 39s\n",
      "119:\ttotal: 37.7s\tremaining: 5m 38s\n",
      "120:\ttest: 0.7169282\tbest: 0.7185297 (90)\ttotal: 38s\tremaining: 5m 38s\n",
      "121:\ttotal: 38.2s\tremaining: 5m 37s\n",
      "122:\ttotal: 38.5s\tremaining: 5m 37s\n",
      "123:\ttotal: 38.9s\tremaining: 5m 37s\n",
      "124:\ttotal: 39.2s\tremaining: 5m 37s\n",
      "125:\ttest: 0.7168270\tbest: 0.7185297 (90)\ttotal: 39.5s\tremaining: 5m 36s\n",
      "126:\ttotal: 39.8s\tremaining: 5m 36s\n",
      "127:\ttotal: 40.1s\tremaining: 5m 36s\n",
      "128:\ttotal: 40.5s\tremaining: 5m 36s\n",
      "129:\ttotal: 40.8s\tremaining: 5m 35s\n",
      "130:\ttest: 0.7171836\tbest: 0.7185297 (90)\ttotal: 41.1s\tremaining: 5m 35s\n",
      "131:\ttotal: 41.4s\tremaining: 5m 35s\n",
      "132:\ttotal: 41.8s\tremaining: 5m 35s\n",
      "133:\ttotal: 42.1s\tremaining: 5m 34s\n",
      "134:\ttotal: 42.4s\tremaining: 5m 34s\n",
      "135:\ttest: 0.7165151\tbest: 0.7185297 (90)\ttotal: 42.7s\tremaining: 5m 34s\n",
      "136:\ttotal: 43s\tremaining: 5m 33s\n",
      "137:\ttotal: 43.4s\tremaining: 5m 33s\n",
      "138:\ttotal: 43.7s\tremaining: 5m 33s\n",
      "139:\ttotal: 44s\tremaining: 5m 32s\n",
      "140:\ttest: 0.7162738\tbest: 0.7185297 (90)\ttotal: 44.3s\tremaining: 5m 32s\n",
      "bestTest = 0.7185296714\n",
      "bestIteration = 90\n",
      "Shrink model to first 91 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1dcc276d450>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = [col for col in x_train.columns if x_train[col].dtype.name == 'category' or x_train[col].dtype.name == 'object']\n",
    "\n",
    "for col in cat_features:\n",
    "    x_train[col] = x_train[col].cat.add_categories('Missing').fillna('Missing')\n",
    "    x_valid[col] = x_valid[col].cat.add_categories('Missing').fillna('Missing')\n",
    "\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=1200,                 \n",
    "    depth=12,                        \n",
    "    learning_rate=0.1,               \n",
    "    eval_metric='AUC',               \n",
    "    random_seed=42,                  \n",
    "    bootstrap_type='Bayesian',       \n",
    "    bagging_temperature=1,           \n",
    "    od_type='Iter',                  \n",
    "    od_wait=50,\n",
    "    task_type='GPU'\n",
    ")\n",
    "\n",
    "cat_model.fit(\n",
    "    x_train, y_train,\n",
    "    eval_set=(x_valid, y_valid),\n",
    "    cat_features=cat_features,\n",
    "    use_best_model=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7185297670089263"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pred = cat_model.predict_proba(x_valid)[:,1]\n",
    "roc_auc_score(y_true=y_valid, y_score=cat_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use randomized search instead of linear search to save time\n",
    "def RandomizedSearch(n_init, pred1, pred2, pred3, y_true, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    weight1 = np.arange(1, 20, 1)\n",
    "    weight2 = np.arange(1, 20, 1)\n",
    "    weight3 = np.arange(1, 20, 1)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['weight1', 'weight2', 'weight3', 'score'])\n",
    "    for i in range(n_init):\n",
    "        # pick weight\n",
    "        w1 = np.random.choice(weight1, replace=True) \n",
    "        w2 = np.random.choice(weight2, replace=True) \n",
    "        w3 = np.random.choice(weight3, replace=True) \n",
    "        \n",
    "        y_ensemble = (w1*pred1 + w2*pred2 + w3*pred3)/(w1+w2+w3)\n",
    "        score = roc_auc_score(y_true=y_true, y_score=y_ensemble)\n",
    "        \n",
    "        df.loc[i] = [w1, w2, w3, score]\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight1</th>\n",
       "      <th>weight2</th>\n",
       "      <th>weight3</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.728308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.728060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.727654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.727618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.727483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.710792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.707327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.704649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.703595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.698926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    weight1  weight2  weight3     score\n",
       "17     16.0      4.0      6.0  0.728308\n",
       "12     19.0      7.0     11.0  0.728060\n",
       "19     13.0      4.0      3.0  0.727654\n",
       "45     12.0      4.0      3.0  0.727618\n",
       "33     17.0      7.0     17.0  0.727483\n",
       "..      ...      ...      ...       ...\n",
       "69      2.0     19.0      5.0  0.710792\n",
       "16      4.0     18.0      2.0  0.707327\n",
       "6       1.0     18.0      3.0  0.704649\n",
       "28      2.0     12.0      1.0  0.703595\n",
       "39      1.0     13.0      1.0  0.698926\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = RandomizedSearch(n_init=100, pred1=pred, pred2=xgb_pred, pred3=cat_pred, y_true=y_valid, random_state=8787)\n",
    "df.sort_values(by=['score'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
